---
title: "Основы Статистики"
author: "Анатолий Карпов"
output:
  html_document:
    highlight: tango
  pdf_document: default
  word_document: default
header-includes: \usepackage[english, russian]{babel}
---

```{r setup, include = F}
library(ggplot2)
library(dplyr)
knitr::opts_chunk$set(message = F, warning = F, cache = T)
```
# 1. Введение (первая неделя)
## 1.1 Информация о курсе
Этот курс посвящен введению в статистику. Этот курс будет состоять из трех недель:

* **первая неделя** -- вводная, поговорим о базовых понятиях - выборка, генеральная совокупность, описательные статистики; разберемся с фразой Статистически значимые различия
* **вторая неделя** -- регерессионный анализ, t-критерий, ANOVA
* **третья неделя** -- корреляция и регрессия


## 1.2 Генеральная совокупность и выборка
### 1.2.1 План урока
* Понятие генеральной совокупности и выборки, репрезентативность выборки
* Простая случайная выборка
* Стратифицированная выборка
* Групповая выборка

### 1.2.2 Лекция
**Генеральная совокупность** -- множество всех тех объектов, относительно
которых мы будем делать выводы.

Например статистика по росту вех людей побывавших на луне; **ГС** будет все эти люди, их легко посчитать, изиерить рост и т.д. Но в большинстве случаев объемы **ГС** очень велики (в некоторых биологических исследованиях объем популяции может насчитывать несколько тысяч представителей). Для того чтобы решить эту проблему исследователь выбирает только часть **ГС** т.е. формирует **выборку**:

**Выборка** -- часть **ГС**, результаты исследования которой можно обообщить на **ГС**.

Очень важным условием является репрезентативность выборки, т.е. мы хотим чтобы наша **выборка** была моделью **ГС**, отражала свойства **ГС**.

Чтобы этого добиться существует несколько вариантов формирования репрезентативной выборки.

### 1.2.3 Задача
Если мы провели исследование с целью выявить уровень знаний в области биологии на 100 студентах биологического факультета СПбГУ, то на какую совокупность мы можем распространить наши выводы?

**Варианты ответов:**

* Студенты СПБГУ
* **Студенты биологического факультета СПБГУ**
* Мужчины и женщины в возрасте от 18 до 22 лет

### 1.2.4 Задача
Если объем выборки достаточно велик (больше 100), то такая выборка является репрезентативной?

**Варианты ответов:**

* Да
* Нет
* **Зависит от способа формирования выборки**

### 1.2.5 - 1.2.7 Лекции
Виды выборок:

* **Простая случайная выборка (simple random sample)** -- случайным образом выбираем элементы **ГС**; чем больше будет объем выбранных объектов, тем сильнее наша выборка будет походить на **ГС** по своим характеристикам.
* **Стратифицированная выборка (stratified sample)** -- разбиваем **ГС** на несколько обособленных групп (strat) различных по своей природе, а уже после осуществляем выборку.
* **Групповая выборка (cluster sample)** -- разбиваем **ГС** на кластеры очень похожие между собой и уже из них случайным образом осуществляем выборку.

### 1.2.8 Задача
Соотнесите способы формирования выборки с предложенными примерами.

**А**. Для того чтобы протестировать курс по введению в статистику и выяснить, насколько хорошо с ним справятся студенты Института биоинформатики, случайным образом было выбрано 50 студентов института.

**Б**. Для исследования взаимосвязи риска развития заболевания и группы крови человека потенциальных участников исследования разделили на четыре группы (в соответствии с группой крови). Затем из каждой группы случайным образом извлекли по 50 человек.

**В**. Чтобы проверить знания школьников Санкт-Петерубрга по математике, было организовано исследование. Случайным образом было выбрано 10 школ, затем из каждой школы случайным образом было отобрано по 50 учащихся разных классов.

Ответы:

* А -- Простая случайная выборка (random sample)
* Б -- Стратифицированная выборка (stratified sample)
* В -- Групповая выборка (cluster sample)

### 1.2.9 Задача
Предположим, после лекции по статистике, один студент решил выяснить, как хорошо **студенты психологического факультета** разбираются в этом предмете. Он подготовил серию заданий и пригласил 30 своих друзей с факультета принять участие в тестировании. Исследователь утверждает, что он сформировал простую случайную выборку. Так ли это?

* **Это не простая случайная выборка. Не каждый член генеральной совокупности мог равновероятно принять участие в тестировании, т.к. исследователь позвал только своих друзей**.
* Такая выборка должна рассматриваться, как стратифицированная выборка. Можно сказать, что исследователь разделил всех студентов на страты по 30 человек и выбрал только одну из них для исследования.
* Такая выборка может рассматриваться, как простая случайная выборка. Тридцать человек действительно являются студентами данного факультета.

## 1.3 Типы переменных
### 1.3.1 План урока

* Типы переменных
* Количественные переменные
* Номинативные переменные
* Ранговые переменные

### 1.3.2 - 1.3.4 Лекции
Глобально все переменные можно разделить на два типа -- **количественные** и **качественные** (номинативные).

**Количественные переменные** -- измеренные значения некоторого признака. Если переменная может принимать любое значение на промежутке, то такая переменная называется **непрерывной**. Например рост испытуемых может оказаться в промежутке от 160 до 190 см. **Дискретные** количественные переменные принимают только определенные значения. Например количество детей в семье.

**Номинативные** (качественные) переменные используются для разделения наших испытуемых (объектов) на группы. Например, все участники женского пола будут обозначены цифрой **1**, а участники мужского пола - цифрой **2**.

В номинативных переменных за цифрами не стоит никакого математического смысла. В данном случае цифры это всего лишь маркеры или лейблы, которые делят наших испытуемых на группы.

### 1.3.5 Задача
Какие из перечисленных переменных, вероятнее всего, являются дискретными?

* **Число слушателей онлайн курса по статистике, набравших максимальный балл**
* Пол человека
* Имена ваших друзей
* Средний годовой доход
* Расстояние от Санкт-Петербурга до других городов России
* **Количество домашних животных в семье**

### 1.3.6 Лекция
**Ранговые переменные** -- упорядоченные дискретные перменные. Например финиширующие в марафонском беге.

### 1.3.7 Задача
Два основных типа переменных в статистике:

* Непрерывные и количественные
* **Качественные и количественные**
* Качественные и номинативные
* Ранговые и номинативные

### 1.3.8 Задача
Соотнесите примеры переменных и их типы:

* Количественная (дискретная) переменная -- Количество публикаций у ученого
* Количественная (непрерывная) переменная -- Рост в мм
* Ранговая переменная -- Успевавемость студентов (упорядоченный список студентов по успеваемости)
* Номинативная переменная -- Группа крови

### 1.3.9 Задача
Если рост 10 участников исследования представлен в ранговой шкале (по убыванию: 1-самый высокий, 2 - ниже и т.д.), тогда верным утверждением будет:

* Испытуемый с рангом 4 на два см ниже, чем испытуемый с рангом 6.
* Ни одно из утверждений верным не является.
* У испытуемых с рангом 1 и 3 такая же разница в росте, как и у испытуемых с рангами 3 и 5.
* **Испытуемый с рангом 4 выше, чем испытуемый с рангом 6, но ниже, чем испытуемый с рангом 2.**

## 1.4 Меры центральной тенденции
### 1.4.1 План урока

* Понятие описательной статистики
* Мода
* Медиана
* Среднее значение
* Выбор меры центральной тенденции
* Свойства среднего

### 1.4.2 Лекция
**Эмпирические данные** -- данные полученные опытным путём.

**Описательная (дескриптивная) статистика** -- обработка данных полученных эмпирическим путём и их систематизация, наглядное представление в форме графиков, таблиц, а также их количественное описание посредством основных статистических показателей.

**Распределение вероятностей** -- это закон, описывающий область значений случайной величины и вероятность её появления (частоту) в данной области. То есть насколько часто X появляется в данном диапазоне значений.

**Гистограмма частот** -- ступенчатая функция показывающая насколько часто вероятно появление величины в указанном диапазоне значений.

### 1.4.3 Лекция
**Мода (Mode)** -- значение измеряемого признака, которое встречается максимально часто.

```{r, fig.height = 3, echo = F}
# fig.height - размер изображение после knit'a
# цвета для графиков взяты здесь http://colorbrewer2.org/
a <- c(157, 159, 161, 164, 165, 166, 167, 167, 167, 168,
       169, 169, 170, 170, 170, 171, 171, 172, 172, 172,
       172, 173, 173, 175, 175, 177, 178, 178, 179, 185)
d <- data.frame(height = a)                 # основные данные
d_mode <- data.frame(height = rep(172, 4))
g <- ggplot() +
  geom_dotplot(data = d, aes(height)) +
  scale_x_continuous(breaks = seq(155, 190, 5)) +
  scale_y_continuous(limits = c(0, 12.1),    # 12.1 - найдено методом математического подгона
                     breaks = seq(0, 12, 4))
g + geom_dotplot(data = d_mode, aes(height), color = "#1b9e77", fill = "#1b9e77") +
  annotate("text", x = 172, y = 6.5,
           label = "mode = 172", size = 5, color = "#1b9e77")
```

Если из нашей выборки удалить всего одно значение **172**, то она получит три моды.

### 1.4.4 Лекция

**Медиана (Median)** -- значение признака,которое делит упорядоченное множество пополам

Сначала нужно упорядочить выборку, а потом найти такое значени, которое поделит ее на две равные части. Возьмем первые девять элементов нашей выборки:

```{r, fig.height = 3, echo = F}
d_sml <- d %>% slice(1:9)
ggplot(d_sml, aes(height)) +
  geom_vline(data = d_sml, aes(xintercept = median(height)),
             color = "#7570b3", linetype = "dotted", size = 1) +
  geom_dotplot() +
  scale_x_continuous(breaks = seq(155, 168, 1)) +
  scale_y_continuous(limits = c(0, 12.1),
                     breaks = seq(0, 12, 3)) +
  annotate("text", x = 163.5, y = 6,
           label = "median = 165", color = "#7570b3", size = 5)
```

В данном случае четыре слева и четыре справа; медиана равна **165**.

Теперь возьмем все данные:

```{r, fig.height = 3, echo = F}
g + geom_vline(data = d, aes(xintercept = median(height)),
             color = "#7570b3", linetype = "dotted", size = 1) +
  annotate("text", x = 174.6, y = 6,
           label = "median = 170.5", size = 5, color = "#7570b3")
```

Точка, которая будет делить наши данные на две равные части, находится между **170** и **171**; в данном случае медианой будет являться среднее значение двух признаков: $$M_{e} = \frac{170 + 171}{2} = 170.5$$

### 1.4.5 Лекция
**Среднее значение (mean, среднее арифметическое)** -- сумма всех измеренных признаков, деленное на их количество.

```{r, fig.height = 3, echo = F}
g + geom_vline(data = d, aes(xintercept = mean(height)),
             color = "#d95f02", linetype = "dotted", size = 1) +
  annotate("text", x = 174.6, y = 6,
           label = "mean = 170.4", size = 5, color = "#d95f02")
```

Расчет среднего для выборки: $$\bar{x} = \frac{x_1 + x_2 + ... x_{30}}{30} = 170.4$$

Для обозначения среднего в **ГС** используется $M$

### 1.4.6 Лекция
В нашем случае все три меры центральной тенденции оказались очень близки друг к другу

```{r, fig.height = 3, echo = F}
g + geom_dotplot(data = d_mode, aes(height), color = "#1b9e77", fill = "#1b9e77") +
  geom_vline(data = d, aes(xintercept = mean(height)),
             color = "#d95f02", linetype = "dotted", size = 1) +
  geom_vline(data = d, aes(xintercept = median(height)),
             color = "#7570b3", linetype = "dotted", size = 1) +
  annotate("text",
           x = c(175, 167, 175),
           y = c(6, 10, 10),
           label = c("mode = 172","mean = 170.4", "median = 170.5"),
           size = 5,
           color = c("#1b9e77", "#d95f02", "#7570b3"))
```

$\bar{x} = 170.4$ -- среднее
$M_{e} = 170.5$ -- медиана  
$M_{o} = 172$ -- мода  

### 1.4.10 Лекция
Если распределение симметричено, унимодально (одна мода) и не имеет заметных выбросов, то можно использовать любую из мер центральной тенденции; среднее, мода и медиана дадут примерно одинаковые значения.

Однако, если у распределения есть ярковыраженная ассиметрия, заметны выбросы или несколько мод, тогда использование среднего значения может привести к некорректным результатам; гораздо лучше использовать моду или медиану.

### 1.4.11 Задача
В каких случаях вместо среднего значения лучше использовать моду или медиану в качестве центральной тенденции?

* Если распределение является симметричным и унимодальным
* **Если распределение асимметрично**
* **Если присутствуют заметные выбросы**

### 1.4.12 Лекция
**Свойства среднего**

$M_{x + c} = M_{x} + c$ -- если  к каждому значению нашей выборки добавить константу то и среднее значение выборки умеличится на жту константу. Графически это выглядит как смещенная вправо кривая распределения.

$M_{x * c} = M_{x} * c$ -- тоже самое и  с умножением.

$\sum (x_{i} - M_{x}) = 0$ -- сумма отклонений от среднего арифметического равна нулю.

### 1.4.13 Задача
Как соотносятся средние значения двух рядов чисел:

$$
\begin{array}
{rrrrrrrrrrrrrr}
 1 &3 &1 &3 &7 &8 &9 &10 &12 &12 &13 &18 &20 &19 \\
 2 &6 &2 &6 &14 &16 &18 &20 &24 &24 &26 &36 &40 &38
\end{array}
$$

Постарайтесь ответить на вопрос, не рассчитывая средние значения, но используя свойства среднего арифметического

Ответы:

* **Среднее второго ряда чисел в два раза больше**
* Средние значения равны
* Среднее второго ряда чисел в два раза меньше

## 1.5 Меры изменчивости
### 1.5.1 План урока
* Понятие меры изменчивости данных
* Размах
* Дисперсия, стандартное отклонение
* Свойства дисперсии и стандартного отклонения

### 1.5.2 Лекция
### 1.5.3 Лекция
**Размах (Range)** -- разность максимального и минимального значения.

$$R = X_{max} - X_{min} = 185 - 157 = 28$$

**Недостаток**: эта мера показывает изменчивость данных, используя только два крайних значения; любое изменение крйнего значения сильно повляет на меру.

Поэтому гораздо интереснее рассчитать изменчивость данных используя каждое из значений.

### 1.5.5 Лекция
Как же нам использовать все без исключения значения признака для расчета меры изменчивости? Один из возможных вариантов это посмотретть насколько в среднем наши значения отклоняются от среднего значения в нашей выборке.

**Дисперсия (varieace)** -- средний квадрат отклонений индивидуальных значений признака от их средней величины.

$$D = \frac{\sum_{i=1}^n(x_{i} - \bar{x})^2}{n}$$
Но т.к. мы возвели числитель в квадрат, то показатель дисперсии будет превышать реальные отклонения наших наблюдений от среднего по выброрке. Чтобы вернуться к исходным единицам измерения извлечем квадратный корень из получившейся дисперсии и получим **среднеквадратическое отклонение**:

$$\sqrt{D} = \sigma$$

И в отличие от дисперссии $\sigma$ показывает реальное среднее значение наших отклонений от средней величины.

**Различные обозначения:**
$\sigma$ -- ско для **ГС**

sd (standart deviation) -- ско для выборки (или просто **стандартное отклонение**)

Формула для расчета дисперсии **выборки** будет немного другая:
$$D = \frac{\sum_{i=1}^n(x_{i} - \bar{x})^2}{n - 1}$$

### 1.5.7 Задача
Укажите, в какой из выборок наибольшее стандартное отклонение:

(1)  1 3 2 4 5 7 1 8  
(2) **100 300 250 400 230 280 320 112**  
(3) 15 10 13 7 28 31 20 32  

P.S. задание можно решить без расчетов.

### 1.5.8 Лекция
$\text{Выборка: }\begin{array}{rrrrrrr} 1& 2& 2& 3& 4& 4& 5 \end{array}$

$M_x = 3$ -- среднее значение выборки

$D = \dfrac{(1-3)^2+(2-3)^2+(2-3)^2+(3-3)^2+(4-3)^2+(4-3)^2+(5-3)^2}{7-1}$

$D = \dfrac{4+1+1+0+1+1+4}{6}= \dfrac{12}{6} = 2$

$sd = \sqrt{D} = \sqrt{2}= 1.4142$

### 1.5.9 Лекция {#anchor}
**Свойства дисперсии и стандартного отклонения**

Если к каждому элементу нашей выборки прибавить число $c$, то ни дисперсия ни стандартное отклонение не изменятся:

$D_{x+c} = D_x$  
$sd_{x+c} = sd_x$

Если каждый элемент нашей выборки умножить на число $c$, то дисперсия увеличится в $c^2$ раз, а стандартное отклонение увеличится просто в $c$ раз:

$D_{x*c} = D_x*c^2$  
$sd_{x*c} = sd_x*c$

### 1.5.10 Задача
Рассчитайте среднеквадратическое отклонение данных выборочных значений:

$\begin{array}{rrrrrrrrrr} 1 &5 &2 &7 &1 &9 &3 &8 &5 &9\end{array}$

Не забудьте, что при расчете дисперсии и среднеквадратичного отклонения мы вычитаем единицу из общего числа наблюдений!

Решение **1**:
```{r}
x <- c(1, 5, 2, 7, 1, 9, 3, 8, 5, 9)
L <- length(x)   # кол-во элементов в выборке
M <- mean(x)     # среднее значение выборки
D <- sum((x - M) ^ 2) / (L - 1) #  расчет дисперсии
sd <- sqrt(D)    # расчет стандартного отклонения
print(c(D, sd))  # вывод результатов
```

Решение **2** (используя встроенные ф-ии R):

```{r}
D <- var(x)     # расчет дисперсии
sd <- sd(x)     # расчет стандартного отклонения
print(c(D, sd)) # вывод результатов
```

### 1.5.11 Задача
Как соотносятся дисперсии  двух выборок

$$
\begin{array}
{rrrrrrrr}
 1 &3 &5 &6 &6 &7 &9 &11 \\
 5 &7 &9 &10 &10 &11 &13 &15
\end{array}
$$

(Постарайтесь решить данное задание не рассчитывая значения дисперсии, но воспользовавшись одним из свойств)

Ответы:  
* D2 = D1 * 4  
* **D2 = D1**  
* D2 = D1 + 4  

Каждый элемент второй выборки на 4 единицы больше элемента из первой, значит используя первое свойство в [1.5.9 Лекция](#anchor) дисперсии она будет одинакова в обеих выборках.

### 1.5.12 Задача
Как соотносятся стандартные (среднеквадратические) отклонения двух выборок:

$$
\begin{array}
 {rrrrrrrr}
 2 &4 &5 &8 &9 &10 &14 &16 \\
 6 &12 &15 &24 &27 &30 &42 &48
\end{array}
$$
Ответы:  
* SD2 = SD1 / 3  
* SD2 = SD1  
* **SD2 = SD1 * 3**  
* SD2 = SD1 * 9

### 1.5.13 Задача
Может ли показатель стандартного отклонения принимать отрицательные значения?

Ответы:
* **Не может, стандартное отклонение всегда неотрицательное.**
* Может, если все значений выборки отрицательные.
* Может, если все значения в выборке равны друг другу.
* Не может, стандартное отклонение всегда равно нулю.

## 1.6 Квартили распределения и график box-plot
### 1.6.1 План урока
* Квантили распределения
* Квартили
* Box plot

### 1.6.2 Лекция
**Квантили** -- это такие значения признака, котрые делят упорядоченные данные на некоторое число частей.

Например знакомая нам уже **медиана** делит наши данные на две части.

**Квартили распределения** -- это такие три точки, которые делят наши данные на четыре равные части.

### 1.6.3 Лекция

$$
\begin{array}
 {rrrrrrrrrrrrrrr}
 157 &159 &161 &164 &165 &166 &167 &\color{red}{167} &167 &168 &169 &169 &170 &170 &170 \\
 171 &171 &172 &172 &172 &172 &173 &\color{red}{173} &175 &175 &177 &178 &178 &179 &185
\end{array}
$$

**Первый квартиль** -- делит половину до медианы пополам, это $167$.

Медиана -- **второй квартиль**; она равна $170.4$

**Третий квартиль** -- делит половину после медианы пополам, это $173$.  

### 1.6.4 Лекция
**Boxplot** -- визуализация квартилей и не только.

```{r, echo = F}
quart_1 <- quantile(d$height, 0.25)
quart_3 <- quantile(d$height, 0.75)
iqr <- IQR(d$height)
ggplot(data = d) + 
  geom_boxplot(aes(x = "", y = height), width = 0.4) +
  geom_hline(yintercept = c(quart_1 - 1.5 * iqr,
                            quart_1,
                            quart_3,
                            quart_3 + 1.5 * iqr),
             linetype = "dashed", color = "red", alpha = 0.6) +
  annotate("text", 
           color = "red", 
           alpha = 0.8,
           x = c(1.42, 1.42, 1, 1.37, 1.37),
           y = c(quart_1 + 1, quart_3 + 1, 171.5, quart_1 - 1.5 * iqr + 1, quart_3 + 1.5 * iqr + 1),
           label = c("quartile 0.25", 
                     "quartile 0.75",
                     "median",
                     "quartile 0.25 - 1.5*IQR",
                     "quartile 0.75 + 1.5*IQR")) +
  geom_segment(aes(x = 0.7, xend = 0.7, y = quart_1, yend = quart_3),
               color = "red", arrow = arrow(length = unit(0.2, "cm")), size = 0.3) +
  geom_segment(aes(x = 0.7, xend = 0.7, y = quart_3, yend = quart_1),
               color = "red", arrow = arrow(length = unit(0.2, "cm")), size = 0.3) +
  annotate("text", x = 0.67, y = 170, 
           label = "IQR", color = "red", alpha = 0.8) +
  geom_point(data = data.frame(height = c(159, 179)), 
             aes(x = "", y = height), 
             color = "red") +
  annotate("text", 
           color = "red", 
           alpha = 0.8,
           x = 1.05, 
           y = c(159, 179, 185, 157), 
           label = c("159", "179", "185", "157"))
```

На рисунке выше представлен график `boxplot` (черного цвета), который получается при выполнеии простого кода: `ggplot(data = d) + geom_boxplot()`, все поясняющие элементы красного цвета нарисованы отдельно. 

Нижняя и верхняя границы "ящика с усами" это соответственно **первый и третий квартили**.

Разница между ними называется **межквартильным размахом (IQR)**.

Линия в самом ящике -- это медиана. 

Вертикальные линии доходят до последних значений (красные точки 159 снизу и 179 сверху), попадающих в интервал $\pm 1.5 \times{IQR}$. 

Значения не попавшие в этот интервал называются **выбросами**; черные точки 157 и 185.

### 1.6.5 Лекция
Если на `boxplot` нанести сами данные, то мы увидим вот такую картину:

```{r, echo = F}
ggplot(data = d, aes(x = "", y = height)) + 
  geom_boxplot() +
  geom_jitter(position = position_jitter(width = 0.3, height = 0),
              shape = 18, 
              color = "red", 
              alpha = 0.8, 
              size = 2.5)
```

## 1.7 Нормальное распределние
### 1.7.1 План урока
* Понятие нормального распределения
* Стандартизация
* Правила двух и трех сигм, использование стандартизации

### 1.7.2 Лекция
Отлично, мы познакомились с описательными статистиками и теперь без труда сможем описать наши данные как с точеи зрения выраженности некоторого количественного признака, так и с точки зрения изменчивости переменной.

**Нормальнрое распределение** -- унимодально, симметрично; отклонения наблюдений от среднего значения равновероятны и подчиняется вероятностному закону отклонения наблюдений от среднего значения. 

От $\mu$ (среднее) до $1\sigma$ (стандартное отклонение) -- $34,1\%$  
От $1\sigma$ до $2\sigma$ -- $13.6\%$  
От $2\sigma$ до $3\sigma$ -- $2.1\%$  
Свыше $3\sigma$ -- $0.1\%$

Для отрицательной половины те же цифры.

### 1.7.3 Лекция
Интересен тот факт, что в реальном мире большое количество характеристик и переменных распределены нормальным образом. И интересно не то, что распределение симметрично, а то, что сохраняются вероятностное расределение. 

И этот вероятностный закон предоставляет нам очень интересные возможности для статистического анализа.

Давайте познакомимся сэтим законом поподробнее, и для этого нам надо узнать, что такое z-стандартизация.

**Z-преобразование**  или **Стандартизация** -- преобразование полученных данных в стандартную Z-шкалу (Z-scores), где среднее значение это $0$, а $\sigma$ это $1$.

Какой бы мы признак не измерили, данные всегда можно представить таким образом.


### 1.7.4 Задача
Если отдельное наблюдение в нашей выборке равняется 1000, при условии, что выборочное среднее равняется  10, то такое наблюдение:

* Можно рассматривать как необычное (выброс), т.к. оно очень далеко отклоняется от среднего значения
* Такое наблюдение в принципе не может принадлежать выборке со средним значением равным 10, так как в 100 раз больше, чем выборочное среднее, а вероятность такого события стремится к нулю
* **Чтобы судить о том, насколько необычным является это наблюдение, необходимо знать, чему равняется стандартное отклонение.**

### 1.7.5 Лекция
Как же нам любые данные преобразовать в такую шкалу, где среднее равно нулю, а дисперсия -- единице?

Формула для преобразования в **Z-score**:
$$z_i=\frac{x_i-\bar{x}}{\sigma_x}$$

И для выборки:
$$z_i=\frac{x_i-\bar{X}}{sd_x}$$

##### Разберем числитель
Мы из каждого наблюдения нашей выборки должны вычесть среднее значение по этой выборке. Подставим среднее значение в формулу и получим: $$\bar{x}-c=\bar{x}-\bar{x}=0$$


##### Разберем знаменатель
А теперь разделим нашу разницу на сигму $\sigma_x$, или умножим на $\dfrac{1}{\sigma_x}$. Т.к. числитель уже равен нулю, то это ни на что не повлияет.

А что случится с дисперсией? Дисерсию нужно умножть на квадрат этого числа, и тогда мы получим:
$$D_x\times\Big(\frac{1}{\sigma_x}\Big)^2=D_x\times\frac{1}{D_x}=1$$
Итак, если мы из каждого наблюдения нашей выборки вычтем среднее и поделим получившееся число на стандартное отклонение, мы получм z-шкалу, где новое среднее станет равно нулю, а дисперсия единице.

Такое преобразование никак не изменит форму распределения. Давайте сравним графики до и после z-преобразования:

```{r echo=F, fig.height = 3}
# Основа для графиков
g2 <- ggplot() + scale_y_continuous(limits = c(0, 12.1), breaks = seq(0, 12, 4))
# Изначальный график
g2 + geom_dotplot(data = d, aes(height))
# График преобразованный в Z-score
g2 + geom_dotplot(data = d, aes(scale(height)))
```

### 1.7.6 Задача
Z-преобразование часто используется, чтобы все наблюдения перевести в z-шкалу (M = 0, sd = 1) для упрощения работы с данными. Однако иногда нам необходимо рассчитать z-значение только для отдельно взятого наблюдения, чтоб выяснить насколько далеко оно отклоняется от среднего значения в единицах стандартного отклонения.

Вернемся к нашему примеру с ростом людей. Допустим, мы измерили рост 1000 человек, данное распределение оказалось нормальным со средним равным 175 и стандартным отклонением равным 8 (M = 175, sd = 8). Рост одного из испытуемых составил 186,2. Чему равняется **z-значение**, рассчитанное для этого испытуемого?

```{r}
M <- 175
sd <- 8
x_i <- 186.2

(z_i <- (x_i - M)/sd)
```

### 1.7.7 Задача
Если отдельное наблюдение меньше, чем выборочное среднее, то соответствующее **z - значение** будет:

* **отрицательным**
* положительным
* нулем
* в зависимости от значения стандартного отклонения возможны все три варианта

### 1.7.8 Задача
Выберите верные утверждения (одно или несколько):

* Z значение может быть рассчитано без знания стандартного отклонения по выборке
* Z значение не может быть больше трех
* **Для каждого наблюдения в выборке можно рассчитать соответствующее z значение**
* **Если для некоторого наблюдения z значение равняется нулю, следовательно это наблюдение совпадает со средним значением по выборке**

### 1.7.9 Лекция
Мы уже говорили, то наше значение отличается от среднего в соответствии с некоторым вероятностным законом, например: 
$M_x \pm \sigma \approx 68\%$ наблюдений  
$M_x \pm 2\sigma \approx 95\%$ наблюдений  
$M_x \pm 3\sigma \approx 100\%$ наблюдений  

Это называется **Правило "двух" и "трех" сигм**.

### 1.7.10 Лекция
Z-преобразование позволяет нам ответить на вопрос какой процент наблюдений лежит в интересующем нас диапазоне.

Допустим у нас есть выборка со средним равным 150, стандартной ошибкой равной 8 и мы хотим узнать **процент наблюдений превосходящих значение 154**.

Для начала сделаем z-преобразование: $$z=\frac{154-150}{8}=0.5$$

Смотрим специальную таблицу [Complementary cumulative](https://en.wikipedia.org/wiki/Standard_normal_table), либо решаем в R:
```{r}
pnorm(q = 154, mean = 150, sd = 8, lower.tail = FALSE)
# q - квантиль
# mean - среднее
# sd - стандартное отклонение
# lower.tail = F - считается вероятность превышения, иначе вероятность НЕпревышения 
```

т.е. вероятность примерно 30%.

Вероятность встретить значение превосходящее 0,5 по z-шкале составляет приблизительно 30%.

### 1.7.11 Задача
Допустим, что некоторый признак распределен нормально, выборочное среднее равняется 100, а дисперсия равняется 25 (M = 100, D = 25). Тогда приблизительно 95% всех наблюдений находится в диапазоне:

* от 50 до 100
* от 50 до 150
* **от 90 до 110**

т.е. $95\%\ попадают\ в\  M\pm2\sigma = M\pm2\sqrt{D}=100\pm2\sqrt{25}=100\pm10$

### 1.7.12 Задача
Считается, что значение IQ (уровень интеллекта) у людей имеет нормальное распределение со средним значением равным 100 и стандартным отклонением равным 15 (M = 100, sd = 15).

Какой приблизительно процент людей обладает IQ > 125?

```{r}
pnorm(q = 125, mean = 100, sd = 15, lower.tail = F)
# или вот так
1 - pnorm(q = 125, mean = 100, sd = 15)
```

##### Ответ
Примерно 5% людей обладают IQ выше 125.

### 1.7.13 Задача
Считается, что значение IQ (уровень интеллекта) у людей имеет нормальное распределение со средним значением равным 100 и стандартным отклонением равным 15 (M = 100, sd = 15).

Какой приблизительно процент людей обладает IQ на промежутке от 70 до 112 

Решение: необходимо вычесть из вероятности превышения 70 вероятность превышения 112

```{r}
pnorm(q = 70, mean = 100, sd = 15, lower.tail = F) - 
  pnorm(q = 112, mean = 100, sd = 15, lower.tail = F)
```

Ответ: примерно 77%

## 1.8 Центральная предельная теорема
### 1.8.1 План урока
[Ссылка](https://gallery.shinyapps.io/CLT_mean/) на сайт с симуляцией данных для центральной предельной теоремы

### 1.8.2 Лекция
В ситуации нормального распределения мы без труда сможем рассчитать вероятность того, что отклонения от среднего превысит некую величину.

Держа в уме это правило, давайте познакомимся с **ЦПТ** которая лежит в основании самой идеи статистической проверки гипотез и наконец разберемся, что означает фраза *"Статистически значимое различие"*.

### 1.8.3 Лекция
Допустим некий признак распределен нормально в **ГС** и имеет среднее значение равное нулю $\mu=0$ и стандартное отклонение равное 15 $\sigma=15$. Давайте будем многократно извлекать выборки из нашей **ГС** по 35 наблюдений в каждой и внутри каждой из выборок рассчитывать среднее значение и стандартное отклонение.

Если посмотреть на гафики распределения признака в выборках, то видно, что их форма разная. Т.е. распределение признака изменяется от выборки к выборке. При этом значение средних так же варьируется. Где-то это положительное отклонене от реального показателя, где-то отрицательное; где-то это более точные оценки, где-то отклонения значительны.

Но что произойдет, если мы посчитаем среднее значение для каждой из выборок и построим распределение выборочных средних значений? 

Мы получи следующую картину. Если внутри каждой из выборок оценка реального показателя может быть не столь точной, то **всреднем** *выборочные средние* значения предоставят довольно неплохой показатель. И **среднее** всех средних будет очень близко к *реальному среднему ГС*.

Мы видим (на графике), что большинство выборочных средних лежит рядом с нулем (истинным средним в ГС), и какие-то отклоняются в положительную сторону, а каие-то в отрицательную. 

Стандартное отклонение этого распределения (выборочных средних) называется **стандартной ошибкой среднего** ($\text{sd от } \bar{x}$) или SE (standart error). 

SE показывает насколько всреднем выборочное значение отклоняется от среднего ГС. 

##### Увеличим размер выборок
Что призойдет, если увелчить объем каждой из выборок? Во-первых, распределение признкак в каждой из групп стало напоминать картиу из ГС. Выборочные оценки (средние и стандартные отклонения в выборках) так же стали более точными.

Но если посмотрим на распределение средних выборочных значений, то мы увидим, что стандартная ошибка сильно уменьшилась.


### 1.8.4 Лекция

### 1.8.5 Задача
Если увеличить размер выборки, то сильные отклонения выборочных средних от истинного среднего будут возникать

* Чаще, распределение выборочных средних станет более широким
* **Реже, распределение выборочных средних станет более узким** 
* Это не повлияет на характер распределения выборочных средних

### 1.8.6 Лекция
Давайте сформулируем **ЦПТ**.

Предположим исследуемы нами признак имеет нормальное распределение в **ГС** со средним значением ($\mu=0$) и стандартным отклонением ($\sigma=20$) 

Мы многократно извлекаем $m$ выборок с объемом наблнюдений $n$. Для каждой выборки рассчитываем её среднее значение $\bar{X_1},\bar{X_2}...\bar{X_m}$ и строим распределение этих выборочных средних. 

Так вот  такое распределение будет являться **нормальным** со средним совпадающим со значением среднего в **ГС** $M=\mu$ и со стандартным отклонением от среднего, которое называется **стандартной ошибкой среднего**: $$se=\frac{\sigma}{\sqrt{n}}$$

Чем больше наблюдений в выборке, тем ближе все выборочные средние к реальному среднему **ГС**. Поэтому изменчивость всех выборочных средних будет тем больше, чем меньше элементов в **ГС**. И чем меньше изменчивость признака в **ГС**, тем реже будут возникать сильные отклонения выборочных средних от среднего в **ГС**.

Чем больше число наблюдений ($\sqrt{n}$) и чем меньше изменчивость **ГС** ($\mu$), тем меньше будет **стандартная ошибка среднего** ($se$).

Если число элементов в выборке $n>30$, выборка репрезентативна, то вместо стандартного отклонения **ГС** можно использовать стандартное отклонение нашей выборки: $$se=\frac{sd_x}{\sqrt{n}}$$

Предположи мы сделали одну выборку со значениями $n=100; sd= 5; \bar{X}=3$. Основываясь на данных только одной выборки мы можем предположить как бы вели себя все выборочные средние, если бы мы многократно повторяли выборку. $$se=\frac{5}{\sqrt{100}}=0.5$$

Так, имея на руках только одну выборку мы можем предсказать как бы вели себя все выборочные средние; они распределились бы вокруг среднего **ГС** $M$ (нам не известного) со стандартной ошибкой среднего $se=0.5$

### 1.8.7 Задача
Рассчитайте стандартную ошибку среднего, если выборочное среднее равняется 10, дисперсия 4, при N = 100
```{r, echo = T}
n <- 100
D <- 4
(se <- sqrt(D/n))
```

### 1.8.8 Задача
Как соотносятся стандартная ошибка среднего и выборочное стандартное отклонение исследуемого признака?

* Стандартная ошибка всегда больше, чем стандартное отклонение
* Стандартная ошибка всегда равняется стандартному отклонению
* **Стандартная ошибка всегда меньше, чем стандартное отклонение**

## 1.9 Доверительные интервалы для среднего
### 1.9.1 План урока
### 1.9.2 Лекция
Наша первая статистическая задача для решения которой потребуется знание **ЦПТ** будет связана с построением доверительных интервалов для среднего значения.

Мы начали с того, что целью статистики является возможность сделать выводы о **ГС**, основываясб только на выборочных данных.

Нас интересует чему равняется среднее значение исследуемого признака в **ГС**.

Давайте рассмотрим следующий пример:

Уровень экспрессии некоторого гена измерялся в эксперименте. Ниже представлены результаты 64 наблюдений.

В исследовании приняли участие мужчины и женщины в возрасте от 18 до 30 лет. У них измерили уровень экспресии некоторого гена.

```{r, echo = F}
gen <- c(102, 91, 99, 100, 103, 98, 99, 101, 106, 88, 103, 97, 103, 101,
       101, 91, 104, 105, 105, 100, 101, 91, 99, 98, 107, 102, 100, 97,
       98, 104, 100, 98, 103, 99, 95, 103, 104, 97, 99, 102, 98, 107, 101,
       93, 98, 101, 93, 91, 107, 102, 96, 93, 100, 105, 103, 107, 99, 102,
       106, 102, 94, 104, 103, 103)
gen
```

```{r}
mean(gen) # средне значение
sd(gen)   # стандартное отклонение
```

Нас волнует главный вопрос: *Чему равен показатель среднего значения экспрессии этого гена во всей генеральной совокупности?*

**ГС** -- это все мужчины и женщины в указанном возрастном промежутке. Поэтому исследовать всех этих людей крайне затруднительно.  

Мы не сможем сказать, точное значение среднего в **ГС**, но мы сможем рассчитать такой интервал относительно которого мы можем быть уверены, что в нем есть интересуюший нас параметр.

Итак, мы знаем, что если бы многократно повторяли эксперимент, то все выборочные средние распределились нормальным образом вокруг среднего **ГС** $М$ со стандартной ошибкой среднего $se=\dfrac{sd_x}{\sqrt{n}}$. 

И мы так же знаем, что $95\%$ всех выборочных средних лежали бы в диапазоне $\mu\pm1.96\sigma$ или в нашем случае $\mu\pm1.96se$. Но мы не знаем среднего!

Предположим, что мы рассчитываем показатель для нескольких выборочных средних $\bar{X_1}\pm1.96se$, $\bar{X_2}\pm1.96se$ и т.д., то эти интервалы включали бы в себя среднее значение **ГС**.

Таким образом $95\%$ всех выборочных средних включили бы в себя среднее **ГС**

**Вот откуда 1,96**: нам нужно найти такой z-score, чтобы слева от него лежало 97,5% данных. Почему 97,5%, а не 95%? Потому что нас интересуют центральные 95% данных (синяя полоска под графиком на слайде), на "хвосты" по бокам, которые нам не интересны остается в сумме 5% (= 100% - 95%) или 2,5% на "хвост" (= 5% / 2). Если мы знаем что справа от правой границы центральных 95% лежит 2,5% данных, то логично что слева от этой границы лежит оставшиеся 97,5% данных (=100% - 2.5%)

```{r}
pr <- 95
(koef <- qnorm((100 - (100 - pr)/2)/100))
```

### 1.9.3 Лекция
Таким образом, если бы мы многократно извлекали бы выборки их **ГС**, в каждой выборке рассчитывали среднее значение, и для него свой 95% интервал, т.е. $\bar{X}\pm1.96se$, то в 95% всех случаев такой интервал включал бы в себя среднее значение **ГС**.

Давайте рассчитаем доверительный интервал для нашей выборки:

$\bar{X}=$ `r mean(gen)`  
$sd=$ `r sd(gen)`  
$n=$ `r length(gen)`  

Первое, что нужно вычислить, это стандартную ошибку среднего:  
$se=\dfrac{sd_x}{\sqrt{n}}$

```{r}
(se <- sd(gen)/sqrt(length(gen))) # стандартная ошибка среднего
```

А затем уже обе границы доверительного интервала:  
$left=\bar{X}-1.96se$  
$right=\bar{X}+1.96se$

```{r}
left <- mean(gen) - koef * se   # левая граница доверительного интервала
right <- mean(gen) + koef * se  # правая граница доверительного интервала
c(left, right)
```

### 1.9.4 Задача
Если мы рассчитали 95% доверительный интервал для среднего значения, то какие из следующих утверждений являются верными?

* **Если многократно повторять эксперимент, для каждой выборки рассчитывать свой доверительный интервал, то в 95 % случаев истинное среднее будет находиться внутри доверительного интервала.**
* Если многократно повторять эксперимент, то 95 % выборочных средних значений будут принадлежать рассчитанному нами доверительному интервалу.
* **Мы можем быть на 95% уверены, что среднее значение в генеральной совокупности принадлежит рассчитанному доверительному интервалу.**
* Среднее значение в генеральной совокупности точно принадлежит рассчитанному доверительному интервалу.
* Среднее значение в генеральной совокупности точно превышает нижнюю границу 95% доверительного интервала.

### 1.9.5 Лекция
Рассчитав такой интервал, мы на 95% можем быть уверены, что него попадет наше среднее ГС. В этом и заключается основная идея этого подхода -- мы не можем точно оценить наш параметр, но можем рассчитать вот такой вот интервал для оценки параметров ГС. 

Мы можем увеличить степень нашей уверенности в том, что смогли поймать среднее в ГС. А именно расчитать **более широкий доверительный интервал**.

Если 95% всех наблюдений (при условии номального распределения) находятся в данном диапазоне -- $\mu\pm1.96\sigma$, то 99% всех наблюдений лежит в диапазоне $\mu\pm2.58\sigma$. Такой интервал будет более широким. 
Можно рассчитать больший доверительный интервал.

!!! ГЛЯНУТЬ КОММЕНТЫ!!!!!!

```{r}
pr <- 99
koef <- qnorm((100 - (100 - pr)/2)/100) # 2.575829 - коэф
left <- mean(gen) - koef * se   # левая граница доверительного интервала
right <- mean(gen) + koef * se   # правая граница доверительного интервала
c(left, right)
```

В этот интервал среднее **ГС** попадет с вероятностью 99%.

### 1.9.6 Задача
Если бы в нашем примере мы увеличили объем выборки в два раза (при условии, что показатель стандартного отклонения остался неизменным), то 95% доверительный интервал

* возможны оба варианта
* **стал более узким**
* стал более широким

### 1.9.7 Задача
В центре 95% доверительного интервала, рассчитанного по выборочным значениям, находится:

* Среднее значение генеральной совокупности
* **Выборочное среднее значение**
* Значение стандартной ошибки среднего

### 1.9.8 Задача
Рассчитайте 99% доверительный интервал для следующего примера: $\hat{x}=10 \quad sd=5 \quad n=100$

```{r}
pr <- 99
x_hat <- 10
sd <- 5
n <- 100

se <- sd/sqrt(n)    # стандартная ошибка среднего
koef <- qnorm((100 - (100 - pr)/2)/100)    # точный коэф

left <- x_hat - koef * se    # левая граница интервала
right <- x_hat + koef * se   # правая граница интервала
c(left, right)
```

## 1.10 Идея статистического вывода, p-уровень значимости
### 1.10.1 План урока
* Статистическая проверка гипотез
* Идея статистического вывода
* p-уровень значимости и его интерпретация

### 1.10.2 Лекция
При помощи доверительных интервалов мы научились решать довольно интересную статистическую задачу. А именно оценивать неизвестный параметр в **ГС**. Но это редко когда является самоцелью. 

В большинстве случаев насинтересуют конкретные гипотезы, возникающие в рамках нашей научной деятельности. Например:

* различаются ли страны по среднему уровню продолжительности жизни?
* можно ли утверждать, что новое лекарство способствует ускорению выздоровления пациентов?
* какие факторы оказывают наиболее сильное влияние на уровень экспрессии генов?

Давайте разберемся с основной идеей, лежащей в основе **статистической проверки гипотез**.

### 1.10.3 Лекция
Давайте разберем один из примеров.

#### Постановка задачи
Предположим, что на выздоровление при некотором заболевании в среднем необходимо $M=20$ дней. Однако, мы разработали новый препарат (НП) и хотим проверить, можно ли сократить этот срок. Мы набрали выборку из $n=64$ пациентов и опробовали на них новый метод лечения. Оказалось, что средний срок выздоровления сократился до $\hat{X}=18,5$ дней, при стандартном отклонении равном $sd=4$.

Какой же вывод можно сделать основываясь на этих данных?

С одной стороны мы действительно сократили срок на выздоровление. С другой стороны интуитивно понятно, что даже при отсутствии какого-либо влияния нашего препарата такой результат мог быть получен совершенно случайно.

#### Гипотезы
Давайте введем два очень важных понятия: $H_0$ и $H_1$.

В нашем исследовании между собою будут конкурировать две гипотезы:

* $H_0$ -- **нулевая гипотеза** говорит о том, что **лекарство никак не повлияло** на выздоровление. И среднее значение времени выздоровления **ГС** тех пациентов, кто использует наш новый препарат не отличается от дватцати $M_{НП}=20$.
* $H_1$ -- альтернативная гипотеза (это то, что нам нужно), говорящая о том, что наш препарат действительно влияет на выздоровление пациентов. Т.е. среднее значение скорости выздоровления в ГС не равняется 20: $M_{НП}\ne20$

#### Предположение, что верна $H_0$
Давайте рассуждать следующим образом, предположим что верна $H_0$. Тогда мы знаем, что в следствии ЦПТ, если бы мы многократно повторяли наше исследование, то выборочные средние распределились бы нормальным  образом вокруг среднего генеральной совокупности $M=20$ и со стандартной ошибкой  $se=\dfrac{sd}{\sqrt{n}}=\dfrac{4}{\sqrt{64}}=0.5$

```{r echo=F, }
ddd <- data.frame(d=rnorm(1e6, mean = 20, sd = 4/sqrt(64)))
ggplot(ddd, aes(d)) +
  geom_density() +
  ggtitle("Распределение выборочных средних") +
  annotate("text", x = 20, y = 0.04, color = "red", label = "M=20", size = 5) +
  annotate("text", x = 18.5, y = 0.65, color = "red", label = "se=sd/sqrt(n)=4/8=0.5", size = 5)
```


Теперь давайте ответим на следующий вопрос: насколько далеко наше выборочное среднее отклонилось от предполагаемого среднего значения в **ГС** в единицах стандартного отклонения?

Для этого сделаем z-преобразование: из нашего выборочного среднего вычтем среднее ГС и разделим на стандаротное отклонение распределения, т.е. на стандартную ошибку седнего. 
$$Z=\frac{\bar{X}-M}{se}=\frac{18.5-20}{0.5}=-3$$

Это означает, что если бы в **ГС** среднее значение на самом деле равнлось бы 20, то наше выборочное среднее отклонилось бы от среднего **ГС** на -3 сигмы в левую стороную.

### 1.10.4 Лекция
Адрес сайта, используемого для расчета p-уровня значимости в следующей лекции:

<https://gallery.shinyapps.io/dist_calc/>

### 1.10.5 Лекция
Давайте воспользуемся свойствами нормального распределения, ятобы рассчитать вероятность такого или еще более выраженного отклонения от среднего значения.

Воспользуемся специальным сайтом, чтобы ускорить этот процесс.

Итак, мы работаем с нормальным распределением; мы сделали z-преобразование, поэтому среднее возьмем равным нулю и стандартное отклонение равное единице. Ведь именно в единицах sd мы рассчитывали отклонение от среднего. 

Задаим необходимые параметры и рассчитаем вероятность такого отклонения $\pm3\sigma$ (решение подсмотрел [тут](http://www.cyclismo.org/tutorial/R/pValues.html)):

```{r}
x_hat <- 18.5
M <- 20
sd <- 4
n <- 64

se <- sd/sqrt(n)
z <- (x_hat - M)/se

p1 <- 2*pnorm(-(abs(z))) # хз зачем тут минус(
p2 <- 2*pnorm(x_hat, mean = M, sd = sd/sqrt(n))
c(p1, p2)
```

Получилась вероятнось отклонения от среднего на три стандартных отклонения (как в **правую** так и в **левую** стороны) равняется приблизительно трем тысячным.

#### Подведем итоги
На первом этапе мы предположили, что верна $H_0$. Если это так, тогда все выборочные средние  распределились бы нормальным образом вокруг среднего генеральной совокупности $M=20$. 

В нашем эксперименте, однако, наше выборочное среднее оказалось равно $\bar{X}=18.5$. 

Зная стандартную ошибку среднего ($se$) мы смогли рассчитать вероятность получить такое или еще более сильное отклонение как в правую так и в левую стороны. Оказалось, что вероятность такого события $p=0.003$

### 1.10.6 Лекция
Таким образом, основная идея статистического вывода заключается в следующем. Сначала мы допускаем, что верна нулевая гипетеза $H_0$ (т.е. нет никаких различий). После этого рассчитывается вероятность того, что мы получили такие или еще более выраженные различия абсолютно случайно.

#### P-value
Эта вероятность в статистике называется **p-уровень значимости**.

И именно при помощи этого показателя мы выясним какую же гипотезу в нашем исследовании считать наиболее обстоятельной.  

Чем **меньше** p-уровень, тем больше оснований **отклонить** $H_0$.

#### Когда принимать альтернативную гипотезу $H_1$?
Считатеся, если $p<0,05$, то можно принимать альтернативную гипотезу.

Однако, если $p>0,05$ считается, что у нас не достаточно оснований отклонить нулевую гипотезу

### 1.10.7 Лекция
Нам удалось получить статистически значимый результат (p-value < 0.05), т.е. вероятность события получить такое или еще более выраженное отклонение отсреднего составляло бы меньше пяти сотых. 

Возникает вопрос, а зачем нам рассчитывать вероятность отклонения в принципиально другом направлении? Если мы проверили гипотезу о том, что наш препарат ускорит выздоровление, то зачем нам вероятность того, что он ее понизит, причем с таким сильным отклонением в правую сторону. 

Вопрос законный и обоснованный. В конце концов, вероятность это площадь под кривой. Если мы будем рассмтривать только одно отклонение, то вероятность такого события будет меньше.

Несмотря на это, в статистике принято учитывать оба конца нашего распределения. Мы не знаем в кукую сторону мы получим отклонение от среднего. Никто не застрахован от обратного результата.

Поэтому, чтобы считать наши результаты статистически достоверными, используется **двусторонний p-уровень значимости**. Он учитывает отклонение в обе стороны. 

Иногда используется односторонний критерий. Это связато с теми случаями, когда, отклонение в одну из сторон просто невозможно. Но таких ситуаций довольно мало. И по большому счету в нашем эксперименте отклонения могут наблюдаться как в правую так и в левую стороны от предполагаемого среднего значения. Поэтму оба конца распределения учитываются для расчета p-уровня значимости.

P-value -- это основной показатель в статистике, который будет на выходе, при использовании различных критериев. И именно благодаря этому показателю, мы будем принимать статистическое решение: отклонять $H_0$ или говорить о том, что у нас недостаточно оснований отклнить её.

Но, зачастую возникают несовсем корректные интерпретации этого значения. 

### 1.10.8 Задача
Все варианты неверны! 

### 1.10.9 Лекция
#### Во-первых
р-уровень значимости не позволяет нам сказать о том, с какой вероятностью верна $H_0$.

Предположим, что мы получили p-value=0.01. Это не значит, что $H_0$ верна с вероятностью 0.01.

Рассмотрим пример: мы подбросили монетку 10 раз и все 10 раз выпал орел! Вероятность такого события $\frac{1}{2}^{10}=0.001$. Так вот, 0.001 это не вероятность того, что монетка у нас честная и работает правильно. Это вероятность того, что если допустить, что наша монтка работает правильно, вероятность такого события - 0.001.

То же самое и с p-value. Если в эксперименте мы полчучили p-value=0.05 -- это означает, что **если** верна нулевая гипотеза, вероятность получить такие или еще более выраженные различия равняется 0.05.

#### Во-вторых
p-value ничего не сообщает о силе нашего эффекта по величине различий. Можно получить довольно значимое различие которое будет очень небольшим, а можно получить сокращение госпитализации на неделю, н оабсолютно не значимое с точки зрения статистики.

Мы еще поговорим, какие факторы будут влиять на саму величину p-value и на величину различий.

#### Что делать, если p-value > 0.05
Какой правильный вывод нужно сформулировать?

В таком случае просто недостаточно оснований, чтобы отклонить нулевую гипотезу.

Если p-value=0.3, это значит, что наши данный неплохо согласуются с $H_0$. Это не значит, что $H_0$ верна, тем олее с вероятностью 30% или 70%. Просто p-value нам не позволяет отклонить нулевую гипотезу.

#### И еще
Сам p-value ничего не говорит ни о правильности, ни о ценности, ни о научности получаемых результатов. 

Статистика это лишь инструмент! 

И сколь угодно идиотскую гипотезу можно рано или поздно подтвердить статистически, бесконечно долго повторяя один и тот же эксперимент, пока чисто случайно мы не получим статистически значимое различие. 

!!!Статья в комментах!!!

### 1.10.10 Лекция
Сама идея поверки статистических гипотез подразумевает наличие статистических ошибок. 

Они называются -- **ошибки статистического вывода** первого и второго рода.

#### Ошибка первого рода
Это когда мы отклонили первую гипотезу, хотя она была верна.

#### Ошибка второго рода
Это когда мы не отклонили нулевую гипотезу, хотя была верна альтернативная.

Далее мы подробнее поговорим, как эти две ошибки влиять на саму процедуру статистической проверке гипотез в различныъ ситуациях. И о том как проверять различные гипотезы, сравнивать несколько групп между собой, говорить о зависимости и вляинии разных переменных друг на друга мы поговрим на протяжении последующих двух недель. 

### 1.10.12 Задача
Использование доверительных интервалов зачастую рассматривают, как альтернативный способ проверки гипотез. В нашем случае, если значение 20 (предполагаемое среднее значение в генеральной совокупности) не будет принадлежать 95% доверительному интервалу, рассчитанному по выборочным данным, у нас будет достаточно оснований отклонить нулевую гипотезу. Проверьте согласуются ли результаты двух этих подходов: рассчитайте 95% доверительный интервал для среднего значения, на примере с тестированием нового препарата.

n = 64,  sd = 4,   M = 18.5

```{r}
n <- 64
sd <- 4
x_hat <- 18.5
se <- sd/sqrt(n)
pr <- 95

koef <- qnorm((100 - (100 - pr)/2)/100)
left <- x_hat - koef * se
right <- x_hat + koef * se
c(left, right)
```

Ответ: 20 не попадает в интервал, поэтому отклоняем $H_0$

### 1.10.13 Задача
Данные некоторого исследования сообщают нам, что средний рост детей в 10 лет составляет 136 сантиметров. Однако это лишь выборочная оценка, и исследователи рассчитали 99% доверительный интервал, который составил [130, 142]. Укажите верные утверждения:

* **У нас достаточно оснований отклонить нулевую гипотезу, что среднее в генеральной совокупности равняется 143**
* Доверительный интервал не может иметь такие границы, т. к. выборочное стандартное отклонение равняется 10, следовательно доверительный интервал должен быть значительно шире.
* **У нас достаточно оснований отклонить нулевую гипотезу, что среднее в генеральной совокупности равняется 128.**
* Вероятность того, что истинное среднее значение больше 142, составляет 0,01

### 1.10.14 Задача
Предположим, нулевой гипотезой вашего исследования являлось предположение, что среднее в генеральной совокупности равняется 100. Вы получили p = 0,12 и не смогли отклонить нулевую гипотезу. Однако позже выяснилось, что среднее в генеральной совокупности равняется 114. Как можно описать результаты данного исследования?

* Вы не совершали ни ошибку первого рода, ни ошибку второго рода.
* **Вы совершили ошибку второго рода**
* Вы совершили ошибку первого рода

### 1.10.15 Задача
В среднем слушатели курса по введению в статистику набирают 115 баллов, однако, в 2015 году средний балл случайно выбранных 144 участников составил 118 со стандартным отклонением равным 9. Рассчитайте p уровень значимости для проверки нулевой гипотезы о том, что среднее значение баллов в 2015 году равняется 115.

```{r}
x_hat <- 118
n <- 144
sd <- 9
M <- 115

p1 <- 2*pnorm(x_hat, mean = M, sd = sd/sqrt(n))
p2 <- 2*pnorm(M, mean = x_hat, sd = sd/sqrt(n)) # вроде это значение правильное
c(p1, p2)
```

# 2. Сравнение средних (вторая неделя)
## 2.1 T-распределение
### 2.1.1 План урока
* Нормальное распределение и ограниченность количества наблюдений
* Распределение Стьюдента (Т-распределение)
* Понятие числа степеней свободы

### 2.1.2 Лекция
Итак, мы познакомились с основной идеей статистической проверки гипотез. Основываясь на **ЦПТ** мы могли предположить, как бы вели себя все выборочные средние, если бы мы многократно повторяли наш эксперимент, и основываясь на этой информации рассчитать вероятность получить такое или еще более сильно выраженное отклонение, чем в нашем исследовании.

Давайте еще раз обратимся к этой теореме.

Если мы знаем, что в нашей **ГС** среднее равняется нулю, а стандартное отклонение равняется единице, и мы многократно извлекаем выборки из **ГС**, то все средние значения этих выборок распределятся нормальным образом вокруг среднего **ГС** со стандартной ошибкой $se=\frac{\sigma}{\sqrt{n}}$, где $n$ -- размер выборки.

Это все очень хорошо и очень удобно, пока у нас достаточно большое коичество наблюдений. Тогда все выборочные средние буду вести себя в соответствии с нормальным распределением.

Однако, все становится гораздо интереснее при малом количестве наблюдений, $N<30$. Нарушается предположение о том, что все выборочные будут вести себя **нормально**.

### 2.1.3 Лекция
Давайте разберемся, почему это произойдет.

Предположим, мы извлекаем большие выборки из ГС, с количеством наблюдений больше сотни. Тогда все наши выборочные средние расределятся нормальным образом вокруг среднего ГС. Это будут нормальные распределения и 95% всех наших выборочных средних буду лежать в диапазоне $\pm 2\sigma$. 

Теперь представим, что мы сильно снизили объем наших выборок и многократно извлекаем выборки по 5 элементов в каждой. В такой ситуации мы будем гоаздо чаще получать выборочные средние, которые довольно далеко отклоняются среднего в ГС.

Чем меньше выборка, тем больше отклонений мы будем получать от среднего ГС. 

### 2.1.4 Лекция
#### Распределение Стьюдента (Т-распределение)
Если число наблюдений невелико и $\sigma$ неизвестно (почти всегда), используется распределение Стьюдента (t-distribution), чтобы описать поведение выборочных средних.

Давайте посмотрим на отличия t-распределения от нормального распределения.
```{r echo=F}
d <- rbind(data.frame(n = rt(1e5, df = 1), type = "t-distr"),
           data.frame(n = rnorm(1e5),      type = "n-distr"))

ggplot(d, aes(n, fill = type)) +
  geom_density(alpha = 0.3) +
  scale_x_continuous(limits = c(-4, 4)) +
  ggtitle("T-distribution vs N-distribution") +
  geom_vline(xintercept = c(-2, 2), linetype = "dotted")
```

Основное отличие в том, что у Стьюдента более высокие хвосты распределения. Это означает, что в диапазоне превышающем $\pm 2 \sigma$.

#### Степени свободы T-распределения
Очень важным прааметром распределения Стьюдента является число степеней свободы. Которое зависит от кол-ва наблюдений в нашей выборке: $df = n-1$. 

Чем больше степеней свободы (а значит и количество наблюдений), тем сильнее t-распределение становится похожим на нормальное распределение.
```{r echo=F}
d <- rbind(data.frame(n = rt(1e5, df = 1),  type = "df=1"),
           data.frame(n = rt(1e5, df = 3),  type = "df=3"),
           data.frame(n = rt(1e5, df = 8),  type = "df=8"),
           data.frame(n = rt(1e5, df = 30), type = "df=30"),
           data.frame(n = rnorm(1e5),      type = "n-distr"))

ggplot(d, aes(n, color = type)) +
  geom_density() +
  scale_x_continuous(limits = c(-4, 4))
```

Чем больше наблюдений мы извлекаем из нашей выборки, тем сильнее распределение Стьюдента сильнее походит на нормальное. 

При $df=30$ t-распределение становится почти нормальным. Но все равно на концах графика t-распределение чуть выше нормального.

### 2.1.5 Задача

### 2.1.6 Лекция
В t-распределении, в отличие от нормального, где отклонение от среднего строго регламентировано, его форма будет меняться в зависимости от числа степеней свободы.

Т.е. получить довольно экстремальное отклонение от среднего значения будет более или менеее вероятно в звасимости от того, насколько большая наша выборка.

Давайте посмотрим, как знание t-распределения повлияет на процесс проверки статистических гипотез.

#### Пример
Доустим, у нас есть основание предполагать, что в ГС среднее равно десяти ($\mu = 10$), а на нашей выборке мы получили среднее $\bar{X}=10.8$, со стандартным отклонением $sd=2$ и на $N=25$ элементах нашей выборки.

Если бы мы пользовались стандартной формулой, то в соответствиис ЦПТ все выбороччные средние распределились бы нормально вокруг среднего ГС $\mu$ и стандартной ошибкой среднего $se=\frac{sd}{\sqrt{n}}$. Подставив данные получим: $\mu=10$, $se=\frac{2}{\sqrt{25}}=0.4$.

Теперь мы хотим посмотреть, как далеко наше выборочное среднее $\bar{X}$ отклонилось от среднего ГС $\mu$ в единицах стандартного отклонения. Найдя этот параметр, мы с легкостью рассчитаем вероятность получить такое или еще более выраженное отклонение.

Для этого нужно найти z-значение. $z=\frac{\bar{X}-\mu}{se}=\frac{10.8-10}{0.4}=2$. Таким образом в нашем эксперименте мы получили отклонение от предполагаемого среднего на 2 стандартных отклонения вправо. 

Давайте теперь найдем вероятность получить такое или еще более выраженное отклонение.

### 2.1.9 Лекция
#### Нормальное распределение
Если бы мы допустили, что все выборочные седние будут распределены нормальным образом, то вероятность получить отклонение превышающее $2\sigma$ (как в левую  так и в правую стороны) составит 0.045:
```{r}
x_hat <- 10.8
mu <- 10
n <- 25
sd <- 2

(p <- 2*pnorm(q = mu, mean = x_hat, sd = sd/sqrt(n)))
```

Это означает, что p-value < 0.05 и мы смело можем отклонить нулевую гипотезу, согласно которой наша выборка принадлежит генеральной совокупности со средним равным 10.

Но как мы сказали, при небольшом объеме выборки распределение выборочных средних будет отличаться от нормального и вероятность получить более выраженное отклонение от среднего станет выше.

#### t-распределение
Давайте рассчитаем данную вероятность, если мы предположим, что мы работаем с t-распределением. Т.к. у нас $N=25$ элементов выборки, значит степеней свободы $df=24$.

И тогда наша вероятность отклонения среднего на 2 сигмы составит уже 0.0569:
```{r}
x_hat <- 10.8
mu <- 10
n <- 25
sd <- 2

(p <- pt(q = mu, df=24, ncp = 0)) # !!! найти правильный расчет
```

Это означает, что используя $p-value=0.0569$ мы бы уже не смогли отклонить нулевую гипотезу.

### 2.1.11 Лекция
Завершая разговор о t-распределении, давайте вернемся к такому понятию как число степеней свободы (degrees of freedom) или df.

В случае с t-распределением оно зависит от количества элементов в нашей выборке $df=n-1$. 

Более общее определение числа степеней свободы: это количество элементов, которые могут варьироваться при расчете некоторого статистического показателя. 

Если у нас есть 10 наблюдений и мы знаем среднее значение по этим наблюдениям, то нам достаточно знать среднее только 9-ти из них, чтобы полностью узнать, чему равен 10-ый оставшийся элемент.

Важно сколько элементов инфрмации мы использовали для расчета того или иного показателя. 

Предположим, что мы знаем среднее в ГС, а в нашей выборке мы получили отклонение в 2 сигмы вправо. Что это может значить? Это может значить совершенно разные вещи. В зависимаости от того, как много элементов мы использовали, чтобы получить это t-значение. Если у нас t-распредеелние с 30-ю степенями свободы, то отклонение на 2 или более сигмы будет приводить, например, к отклонению нулевой гипотезы. А если степеней свободы было всего 3, то будут совсем другие последствия. 

Поэтому при расчете различных статистических показателей **важно** учитывать как много элементов мы использовали, чтобы полчучить значение. И это может приводить к принципиально разным выводам.

Поэтому в статистике в большинстве методов всегда будет указываться число степеней свободы. В большинстве случаев это будет связано с размером выборки, т.е. как много элементов нашей выборки позволили нам сделать оценку того или иного статистического параметра.

### 2.2.2 Лекция
Критерий, который позволяет сравнивать две выборки между собой, иными словами два выборочных средних, называется **парый t-тест** или просто **критерий t-Стьюдента**.

Давайте разберемся, как же работает этот критерий.

### 2.2.3 Лекция
Предположим, мы хотим сравнить два средних выборочных значения. Первое среднее выборочное $\bar{X_1}$, со стандартным отклонением $sd_1$ и числом элементов выборки $n_1$. Второе выборочное: $\bar{X_2}, sd_2, n_2$. 

Сформулируем статистические гипотезы:

* $H_0$ предполагает, что в ГС между этим средними никакого различия нет: $M_1=M_2$;
* $H_1$ предполагает, что в ГС эти средние различны: $M_1 \ne M_2$;

#### Верна $H_0$
Если это так, то при многократном повторении нашего эксперимента (извлечении из ГС двух выборок) и каждый раз рассчитывая разницу выборочных средних $\bar{X_1}-\bar{X_2}$, мы получили бы распределение этих разниц: оно было бы симметричным вокруг соответстыующего значения в ГС.

Если мы предположили, что в ГС два средних равны $M_1=M_2$, то и среднее значение разностей этих средних значений равнялось бы нулю.

При этом стандартное отклонение такого распределения или стандартная ошибка вычислялась бы по формуле: $\sqrt{\dfrac{sd_1^2}{n_1} + \dfrac{sd_2^2}{n_2}}$.

Стандартная ошибка среднего зависит от стандартных отклонений обеих выборок.

При достаточно большом количестве наблюдений распределение разности средних приняло бы нормальный вид. Но еще более точно будет сказать, что такое распределение будет соответствовать t-распределению с числом степеней свобод, рассчитывающейся по следующей формуле: $df=n_1 + n_2 - 2$.

Основываясь на всей этой информации мы можем рассчитать, насколько далеко конкретно наша разность между двумя средними значениями, отклонилась от предполагаемого показателя в генеральной совокупности. 

Тем самым рассчитать вероятность получить такие или еще более выраженные различия при условии, что на самом деле верна $H_0$.

Давайте запишем окончательную формулу t-китерия (t-значения):
$$t=\dfrac{(\bar{X_1}-\bar{X_2})-(M_1-M_2)}{\sqrt{\dfrac{sd_1^2}{n_1} + \dfrac{sd_2^2}{n_2}}}$$

Важный нюанс. Мы предположили, что в ГС средние у нас идентичны, поэтому разность $M_1-M_2=0$, тогда:
$$t=\dfrac{\bar{X_1}-\bar{X_2}}{\sqrt{\dfrac{sd_1^2}{n_1} + \dfrac{sd_2^2}{n_2}}}$$

Рассчитав соответствующее t-значение, и зная количество степеней свободы $df=n_1+n_2-2$, мы можем рассчитать p-уровень значимости который подскажет нам, какая вероятность получить такое или еще большее выраженное различие между двумя средними если на самом деле верна $H_0$

### 2.2.4 Лекция
Реальный пример

Процесс денатурации ДНК представляет разрушение водородных связей между двумя цепями этой молекулы и очень сильно зависит от температуры, с которой мы воздействуем на молекулу.

При сравнении двух видов между собой в исследовании были получены следующие различия в средней температуре плавления ДНК:

```{r echo=F}
v1 <- c(84.7, 105.0, 98.9,  97.9, 108.7, 
        81.3,  99.4, 89.4,  93.0, 119.3, 
        99.2,  99.4, 97.1, 112.4,  99.8, 
        94.7, 114.0, 95.1, 115.5, 111.5)
v2 <- c(57.2, 68.6, 104.4, 95.1,  89.9, 
        70.8, 83.5,  60.1, 75.7, 102.0,
        69.0, 79.6,  68.9, 98.6,  76.0,
        74.8, 56.0,  55.6, 69.4,  59.5)
```


Выборка |  M         | sd       |N
--------|------------|----------|-------------
Вид №1  |`r mean(v1)`|`r sd(v1)`|`r length(v1)`
Вид №2  |`r mean(v2)`|`r sd(v2)`|`r length(v2)`

Как же нам выяснить, являются ли эти различиия статистически значимыми?

Здесь нам поможет Критерий t-Стьюдента

### 2.2.5 Лекция
#### Формулировка гипотез
* $H_0$ -- cредняя температура плавления первого вида равна средней температуре плавления второго вида: $M_1=M_2$
* $H_1$ -- средняя температура плавления ДНК у этих видов не равны: $M_1 \ne M_2

#### Расчет t-критерия Стьюдента
Если бы была верна первая гипотеза, то разность между всеми средними значениями распределилась бы симметричным образом в соответствии с t-распределением и среднее значение этого распределения равнялась бы нулю.

А у нас разность между средними нулю не равняется: 
 
